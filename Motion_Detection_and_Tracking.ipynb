{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9428907f-c50e-4590-8cb0-baab60133960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "390b8614-9aa2-4628-9b32-b819e6722999",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36253c12-82d7-4051-9f55-4dc8826b9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "from collections import deque\n",
    "import multiprocessing\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "623b097b-944b-454c-ad36-4e9ec127a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motion_Detection:\n",
    "    def __init__(self, Video_Capture, deque_maxlen, frame_size):\n",
    "        self.Size = frame_size\n",
    "        \n",
    "        _, first_frame = Video_Capture.read()\n",
    "        first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "        first_frame = cv2.resize(first_frame, (self.Size, self.Size))\n",
    "        first_frame_z = np.zeros_like(first_frame)\n",
    "    \n",
    "        self.d = deque(maxlen=deque_maxlen)\n",
    "        for i in range(deque_maxlen):\n",
    "            self.d.append(first_frame_z)\n",
    "    \n",
    "    \n",
    "    def detect(self, frame):\n",
    "        f_gray = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2GRAY)\n",
    "        f_gray = cv2.resize(f_gray, (self.Size, self.Size))\n",
    "        f_guss = cv2.GaussianBlur(f_gray, (7, 7), 0)\n",
    "        \n",
    "        self.d.append(f_guss)\n",
    "    \n",
    "        frame_diff1 = cv2.absdiff(self.d[-2], self.d[-1])\n",
    "        frame_diff2 = cv2.absdiff(self.d[-3], self.d[-2])\n",
    "\n",
    "        frame_thresh1 = cv2.threshold(frame_diff1, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "        frame_thresh2 = cv2.threshold(frame_diff2, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        thresh_and = cv2.bitwise_and(frame_thresh1, frame_thresh2)\n",
    "        return thresh_and\n",
    "    \n",
    "    def tracking(self, frame_detected, frame_org, Min_Area):\n",
    "        self.cnts, _ = cv2.findContours(frame_detected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for c in self.cnts:\n",
    "            if cv2.contourArea(c) < Min_Area:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame_org, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "            cv2.putText(frame_org, \"Tracking\", (15, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "       \n",
    "        return frame_org\n",
    "    \n",
    "    def Warning(self, warning_TRUEorFALSE, frame_detected, frame_org, sleep):\n",
    "        if warning_TRUEorFALSE == False:\n",
    "            p = multiprocessing.Process(target=playsound, args=(\"warning.mp3\",))\n",
    "            countNoneZero = cv2.countNonZero(frame_detected)\n",
    "            if countNoneZero != 0:\n",
    "                time_ = datetime.datetime.now().strftime(\"-%H-%M\")\n",
    "                cv2.imwrite(f\"tracking{time}.jpg\", frame_org)\n",
    "                p.start()\n",
    "                t1 = time.sleep(sleep)\n",
    "                p.terminate()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45fb623a-e67c-46f9-bf7f-cdc9f26a8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "motionOBJECT = Motion_Detection(cap, 3, 540)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    detected = motionOBJECT.detect(frame)\n",
    "    tracked = motionOBJECT.tracking(detected, frame, 0)\n",
    "\n",
    "    motionOBJECT.Warning(True, detected, frame, 2)\n",
    "    \n",
    "    cv2.imshow(\"motion detection\", tracked)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc420f6-cb5f-4f02-b594-d03b3dbf83ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
